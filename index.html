<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Ruby WASM Sound Visualizer</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: #000;
      font-family: Arial, sans-serif;
    }
    canvas {
      display: block;
    }
    #loading {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      color: white;
      font-family: monospace;
      font-size: 20px;
      text-align: center;
      z-index: 100;
    }
    #status {
      position: fixed;
      bottom: 20px;
      left: 20px;
      color: #0cc;
      font-family: monospace;
      font-size: 10px;
      z-index: 50;
    }
    #vrmUpload {
      margin-top: 30px;
    }
    .vrm-upload-btn {
      display: inline-block;
      padding: 12px 24px;
      background: #222;
      color: #0f0;
      border: 1px solid #0f0;
      border-radius: 4px;
      cursor: pointer;
      font-family: monospace;
      font-size: 14px;
      transition: background 0.3s, color 0.3s;
    }
    .vrm-upload-btn:hover {
      background: #0f0;
      color: #000;
    }
    #vrmFileName {
      margin-top: 10px;
      font-size: 12px;
      color: #888;
    }
    /* VJ Pad prompt overlay */
    #vjPrompt {
      display: none;
      position: fixed;
      bottom: 55px;
      left: 20px;
      right: 20px;
      z-index: 60;
      font-family: monospace;
      font-size: 12px;
    }
    #vjPrompt.active { display: flex; align-items: center; gap: 6px; }
    #vjPromptInput {
      flex: 1;
      background: rgba(0, 0, 0, 0.25);
      color: #0f0;
      border: none;
      border-radius: 3px;
      padding: 4px 8px;
      font-family: monospace;
      font-size: 12px;
      outline: none;
    }
    #vjPromptInput::placeholder { color: #060; }
    #vjPromptResult {
      color: #0f0;
      white-space: nowrap;
      max-width: 40%;
      overflow: hidden;
      text-overflow: ellipsis;
    }
    #vjPromptResult.error { color: #f44; }
    /* Control Panel overlay */
    #controlPanel {
      display: none;
      position: fixed;
      top: 0;
      right: 0;
      width: 300px;
      height: 100vh;
      background: rgba(0, 0, 0, 0.85);
      color: #ccc;
      font-family: monospace;
      font-size: 11px;
      z-index: 80;
      overflow-y: auto;
      border-left: 1px solid #333;
      padding: 8px 12px;
      box-sizing: border-box;
    }
    #controlPanel.active { display: block; }
    #controlPanel .cp-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 8px;
      padding-bottom: 6px;
      border-bottom: 1px solid #444;
    }
    #controlPanel .cp-header h3 {
      margin: 0;
      color: #0f0;
      font-size: 13px;
    }
    #controlPanel .cp-close {
      background: none;
      border: 1px solid #666;
      color: #999;
      cursor: pointer;
      padding: 2px 8px;
      font-family: monospace;
      font-size: 11px;
      border-radius: 3px;
    }
    #controlPanel .cp-close:hover { color: #fff; border-color: #fff; }
    #controlPanel #cpResetBtn:hover { background: #f44; color: #000; border-color: #f44; }
    #controlPanel .cp-group {
      margin-bottom: 10px;
    }
    #controlPanel .cp-group-title {
      color: #0cc;
      font-size: 11px;
      margin: 0 0 4px 0;
      cursor: pointer;
      user-select: none;
    }
    #controlPanel .cp-group-title:hover { color: #0ff; }
    #controlPanel .cp-slider-row {
      display: flex;
      align-items: center;
      gap: 4px;
      margin-bottom: 3px;
    }
    #controlPanel .cp-label {
      width: 100px;
      flex-shrink: 0;
      overflow: hidden;
      text-overflow: ellipsis;
      white-space: nowrap;
      color: #aaa;
    }
    #controlPanel .cp-value {
      width: 42px;
      flex-shrink: 0;
      text-align: right;
      color: #0f0;
      font-size: 10px;
    }
    #controlPanel input[type="range"] {
      flex: 1;
      height: 14px;
      -webkit-appearance: none;
      appearance: none;
      background: #333;
      border-radius: 2px;
      outline: none;
    }
    #controlPanel input[type="range"]::-webkit-slider-thumb {
      -webkit-appearance: none;
      appearance: none;
      width: 10px;
      height: 14px;
      background: #0f0;
      border-radius: 2px;
      cursor: pointer;
    }
    #controlPanel .cp-actions {
      display: flex;
      gap: 6px;
      margin-top: 8px;
      padding-top: 8px;
      border-top: 1px solid #444;
    }
    #controlPanel .cp-btn {
      flex: 1;
      padding: 6px;
      background: #222;
      color: #0f0;
      border: 1px solid #0f0;
      border-radius: 3px;
      cursor: pointer;
      font-family: monospace;
      font-size: 11px;
      text-align: center;
    }
    #controlPanel .cp-btn:hover { background: #0f0; color: #000; }
    #controlPanel .cp-btn.active { background: #0f0; color: #000; }
    #controlPanel .cp-btn.active:hover { background: #0a0; color: #000; }
    /* VRM choice bar (overlaid on preview) */
    #vrmChoiceBar {
      display: none;
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      z-index: 90;
      text-align: center;
    }
    #vrmChoiceBar.active { display: block; }
    #vrmChoiceBar .vrm-title {
      color: #fff;
      font-family: monospace;
      font-size: 16px;
      margin-bottom: 16px;
    }
  </style>
</head>
<body>
  <!-- Tab video background (hidden until tab capture starts) -->
  <video id="tabVideo" autoplay playsinline muted
         style="display:none; position:fixed; top:0; left:0; width:100%; height:100%; object-fit:cover; z-index:-2;"></video>
  <div id="tabOverlay"
       style="display:none; position:fixed; top:0; left:0; width:100%; height:100%; background:rgba(0,0,0,0.5); z-index:-1;"></div>

  <div id="loading">
    <div id="loadingTitle">Loading Ruby WASM Sound Visualizer...</div>
    <div id="loadingStatus" style="font-size: 12px; margin-top: 20px;"></div>
  </div>
  <!-- Hidden file input for VRM loading (triggered by Controls button or Alt+V) -->
  <input type="file" id="vrmFileInput" accept=".vrm" style="display: none;">
  <!-- Control Panel (right side overlay) -->
  <div id="controlPanel">
    <div class="cp-header">
      <h3>Controls</h3>
      <button class="cp-btn" id="cpResetBtn" style="flex:0 0 auto;padding:2px 6px;font-size:10px;color:#f44;border-color:#f44;" title="Reset All">Reset All</button>
      <button class="cp-close" id="cpCloseBtn" title="Close (p)">X</button>
    </div>
    <div class="cp-group" id="cpColorGroup">
      <div class="cp-group-title">Color</div>
      <div style="display:flex;align-items:center;gap:8px;margin-bottom:6px;">
        <canvas id="hueWheel" width="120" height="120"
                style="cursor:crosshair;flex-shrink:0;"></canvas>
        <div>
          <div style="color:#aaa;font-size:10px;">Hue</div>
          <span id="hueValueDisplay" style="color:#0f0;font-size:11px;">0.0°</span>
          <div style="margin-top:6px;">
            <div style="color:#aaa;font-size:10px;margin-bottom:3px;">Mode</div>
            <div id="colorModeButtons" style="display:flex;gap:3px;flex-wrap:wrap;"></div>
          </div>
        </div>
      </div>
      <div class="cp-slider-row">
        <span class="cp-label" title="max_brightness">Brightness</span>
        <input type="range" id="cpSlider_max_brightness" min="0" max="255" step="1" value="255">
        <span class="cp-value" id="cpVal_max_brightness">255</span>
      </div>
      <div class="cp-slider-row">
        <span class="cp-label" title="max_saturation">Saturation</span>
        <input type="range" id="cpSlider_max_saturation" min="0" max="100" step="1" value="100">
        <span class="cp-value" id="cpVal_max_saturation">100</span>
      </div>
    </div>
    <div id="cpSliders"></div>
    <div class="cp-actions">
      <button class="cp-btn" id="cpLoadVrmBtn" title="Toggle VRM (Alt+V)">VRM</button>
      <button class="cp-btn" id="cpCaptureTabBtn" title="Toggle Tab Capture (Alt+T)">Capture Tab</button>
      <button class="cp-btn" id="cpCaptureCameraBtn" title="Toggle Camera Capture (Alt+C)">Capture Camera</button>
      <button class="cp-btn" id="cpPerfViewBtn" title="Open performance view window">Perf View</button>
    </div>
    <div class="cp-audio-source" id="cpAudioSource" style="display:flex;align-items:center;gap:4px;padding:4px 8px;border-top:1px solid #444;margin-top:4px;">
      <span style="color:#888;font-size:10px;">Audio:</span>
      <button class="cp-btn cp-src-btn" id="cpSrcMic" style="padding:2px 6px;font-size:10px;">Mic</button><button class="cp-btn" id="cpMicDeviceBtn" style="padding:2px 4px;font-size:10px;flex:0 0 auto;" title="Select mic device">⚙</button>
      <button class="cp-btn cp-src-btn" id="cpSrcCamera" style="padding:2px 6px;font-size:10px;">Cam Mic</button>
      <button class="cp-btn cp-src-btn" id="cpSrcTab" style="padding:2px 6px;font-size:10px;">Tab</button>
    </div>
  </div>
  <div id="vjPrompt">
    <span style="color: #0f0;">&gt;</span>
    <input id="vjPromptInput" type="text" placeholder="c 1; s 2.0; bm 4.0" autocomplete="off" spellcheck="false">
    <span id="vjPromptResult"></span>
  </div>
  <div id="status">
    <div style="line-height: 1.0;"><span id="fpsCounter">FPS: 0</span>  |  <span id="paramInfo"></span></div>
    <div id="debugInfo" style="margin-top: 1px; line-height: 1.0; white-space: nowrap; overflow-x: auto;"></div>
    <div id="keyGuide" style="margin-top: 1px; line-height: 1.0; color: #888; font-size: 9px; white-space: pre-wrap;"></div>
  </div>

  <!-- Ruby WASM (must load before async module scripts) -->
  <script src="https://cdn.jsdelivr.net/npm/@ruby/4.0-wasm-wasi@2.8.1/dist/browser.script.iife.js"></script>

  <!-- Import Maps で Three.js 依存関係を解決 -->
  <script type="importmap">
{
  "imports": {
    "three": "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js",
    "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/",
    "@pixiv/three-vrm": "https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3/lib/three-vrm.module.min.js"
  }
}
  </script>

  <!-- Three.js とポストプロセッシングをグローバルに登録 -->
  <script type="module">
    import * as THREE from 'three';
    import { EffectComposer } from 'three/addons/postprocessing/EffectComposer.js';
    import { RenderPass } from 'three/addons/postprocessing/RenderPass.js';
    import { UnrealBloomPass } from 'three/addons/postprocessing/UnrealBloomPass.js';
    import { OutputPass } from 'three/addons/postprocessing/OutputPass.js';
    import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
    import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';

    // Ruby から使えるようにグローバルに登録
    window.THREE = THREE;
    window.EffectComposer = EffectComposer;
    window.RenderPass = RenderPass;
    window.UnrealBloomPass = UnrealBloomPass;
    window.OutputPass = OutputPass;
    window.GLTFLoader = GLTFLoader;
    window.VRMLoaderPlugin = VRMLoaderPlugin;
    window.VRMUtils = VRMUtils;
    window.THREE_READY = true;

    console.log('[Three.js] r' + THREE.REVISION + ' loaded with postprocessing + VRM support');
  </script>

  <!-- Ruby Code Blocks (external files) -->
  <script type="text/ruby" src="src/ruby/visualizer_policy.rb"></script>
  <script type="text/ruby" src="src/ruby/math_helper.rb"></script>
  <script type="text/ruby" src="src/ruby/js_bridge.rb"></script>
  <script type="text/ruby" src="src/ruby/frequency_mapper.rb"></script>
  <script type="text/ruby" src="src/ruby/audio_analyzer.rb"></script>
  <script type="text/ruby" src="src/ruby/color_palette.rb"></script>
  <script type="text/ruby" src="src/ruby/particle_system.rb"></script>
  <script type="text/ruby" src="src/ruby/geometry_morpher.rb"></script>
  <script type="text/ruby" src="src/ruby/camera_controller.rb"></script>
  <script type="text/ruby" src="src/ruby/bloom_controller.rb"></script>
  <script type="text/ruby" src="src/ruby/effect_manager.rb"></script>
  <script type="text/ruby" src="src/ruby/effect_dispatcher.rb"></script>
  <script type="text/ruby" src="src/ruby/audio_input_manager.rb"></script>
  <script type="text/ruby" src="src/ruby/keyboard_handler.rb"></script>
  <script type="text/ruby" src="src/ruby/vj_plugin.rb"></script>
  <script type="text/ruby" src="src/ruby/vj_pad.rb"></script>

  <!-- VJ Pad Plugins (src/ruby/plugins/vj_*.rb) -->
  <script type="text/ruby" src="src/ruby/plugins/vj_burst.rb"></script>
  <script type="text/ruby" src="src/ruby/plugins/vj_flash.rb"></script>
  <script type="text/ruby" src="src/ruby/plugins/vj_shockwave.rb"></script>
  <script type="text/ruby" src="src/ruby/plugins/vj_strobe.rb"></script>
  <script type="text/ruby" src="src/ruby/plugins/vj_rave.rb"></script>
  <script type="text/ruby" src="src/ruby/debug_formatter.rb"></script>
  <script type="text/ruby" src="src/ruby/bpm_estimator.rb"></script>
  <script type="text/ruby" src="src/ruby/frame_counter.rb"></script>
  <script type="text/ruby" src="src/ruby/vrm_dancer.rb"></script>
  <script type="text/ruby" src="src/ruby/vrm_material_controller.rb"></script>
  <script type="text/ruby" src="src/ruby/snapshot_manager.rb"></script>
  <script type="text/ruby" src="src/ruby/main.rb"></script>

  <script>
    // === Log Buffer for Chrome MCP Access ===
    // Structured ring buffer accessible from DevTools: window.logBuffer.getLast(20)
    window.logBuffer = {
      entries: [],
      maxSize: 500,
      add(level, source, message) {
        this.entries.push({
          ts: new Date().toISOString().substr(11, 12),
          level, source, message
        });
        if (this.entries.length > this.maxSize) {
          this.entries = this.entries.slice(-this.maxSize);
        }
      },
      getLast(n) { return this.entries.slice(-(n || 20)); },
      getErrors() { return this.entries.filter(e => e.level === 'error'); },
      getRuby() { return this.entries.filter(e => e.source === 'ruby'); },
      getJS() { return this.entries.filter(e => e.source === 'js'); },
      clear() { this.entries = []; },
      dump() {
        return this.entries.map(e =>
          `${e.ts} [${e.level}][${e.source}] ${e.message}`
        ).join('\n');
      }
    };

    // Intercept console methods to capture all output into logBuffer
    ['log', 'warn', 'error'].forEach(method => {
      const original = console[method].bind(console);
      console[method] = function(...args) {
        original(...args);
        try {
          const msg = args.map(a => typeof a === 'object' ? JSON.stringify(a) : String(a)).join(' ');
          const source = msg.startsWith('[Ruby]') ? 'ruby' :
                         msg.startsWith('[JS]') ? 'js' :
                         msg.startsWith('[DEBUG') ? 'debug' : 'other';
          window.logBuffer.add(method === 'log' ? 'info' : method, source, msg);
        } catch (e) { /* ignore logging errors */ }
      };
    });

    // Global state for JavaScript bridge
    let audioContext, analyser, dataArray;
    let scene, camera, renderer, composer;
    let particleSystem, geometryMesh;
    let renderPass, bloomPass;
    let frameCount = 0;  // Used for DOM update throttle only

    // Performance view mode (URL has ?perf=1)
    const IS_PERF_VIEW = new URLSearchParams(window.location.search).has('perf');

    // Capture opacity state
    let capOverlayOpacity = 0.5;
    let capVideoOpacity   = 1.0;

    // Audio input state
    let micGain = null;
    let micDeviceId = null;  // null = default mic
    let micMuted = false;
    let tabStream = null;
    let tabAudioSource = null;
    let tabAudioGain = null;
    let cameraStream = null;
    let camMicStream = null;
    let camMicSource = null;
    let camMicGain = null;

    // VRM state
    let currentVRM = null;
    let animLastTime = Date.now();

    // Camera rotation control (spherical coordinates)
    let cameraTheta = 0;      // Y-axis rotation (horizontal)
    let cameraPhi = 0;        // X-axis rotation (vertical)
    let cameraRadius = 5;     // Distance from target
    let cameraTarget = null;  // Look-at target (initialized in initThree)

    // Selective Bloom (Layer 1 = bloom objects, Layer 0 = non-bloom objects)
    const BLOOM_LAYER = 1;
    let bloomLayer = null;      // Initialize after THREE.js loads
    let darkMaterial = null;    // Initialize after THREE.js loads
    const materials = {};       // Store original materials during bloom pass

    // VRM bone order (must match Ruby VRMDancer::BONE_ORDER)
    const VRM_BONE_ORDER = [
      'hips', 'spine', 'chest', 'head',
      'leftUpperArm', 'leftLowerArm', 'leftHand',
      'rightUpperArm', 'rightLowerArm', 'rightHand',
      'leftUpperLeg', 'leftLowerLeg',
      'rightUpperLeg', 'rightLowerLeg'
    ];

    // Ruby VM is set by browser.script.iife.js as window.rubyVM
    const getRubyVM = () => window.rubyVM;

    // Web Audio API Setup: AudioContext + analyser only (mic not auto-connected)
    async function initAudio() {
      console.log('[JS] Initializing Web Audio API...');
      try {
        if (!audioContext) {
          audioContext = new AudioContext();
        }
        if (audioContext.state === 'suspended') {
          console.log('[JS] AudioContext is suspended, attempting resume...');
          await audioContext.resume();
          console.log('[JS] AudioContext resumed, state:', audioContext.state);
        }
        if (!analyser) {
          analyser = audioContext.createAnalyser();
          analyser.fftSize = 2048;
          analyser.smoothingTimeConstant = 0.5;
        }
        const bufferLength = analyser.frequencyBinCount;
        dataArray = new Uint8Array(bufferLength);
        console.log('[JS] Web Audio API initialized (no mic auto-connect), state:', audioContext.state);
      } catch (error) {
        console.error('[JS] Audio init error:', error);
        throw error;
      }
    }

    // Toggle microphone mute/unmute
    function toggleMic() {
      if (!micGain) return;
      micMuted = !micMuted;
      micGain.gain.value = micMuted ? 0 : 1;
      console.log('[JS] Mic ' + (micMuted ? 'muted' : 'unmuted'));
      if (window.rubyOnMicToggle) window.rubyOnMicToggle(micMuted);
    }

    // Set mic mute state explicitly (0=mute, 1=unmute)
    function setMicMute(mute) {
      if (!micGain) return;
      micMuted = !!mute;
      micGain.gain.value = micMuted ? 0 : 1;
      console.log('[JS] Mic ' + (micMuted ? 'muted' : 'unmuted'));
      if (window.rubyOnMicToggle) window.rubyOnMicToggle(micMuted);
    }

    // Start capturing audio/video from another Chrome tab
    async function startTabCapture() {
      try {
        tabStream = await navigator.mediaDevices.getDisplayMedia({
          video: true,
          audio: true
        });

        // Audio: connect tab audio to analyser via gain node
        const audioTracks = tabStream.getAudioTracks();
        if (audioTracks.length > 0) {
          tabAudioSource = audioContext.createMediaStreamSource(
            new MediaStream(audioTracks)
          );
          tabAudioGain = audioContext.createGain();
          tabAudioGain.gain.value = 1.0;
          tabAudioSource.connect(tabAudioGain);
          tabAudioGain.connect(analyser);
          console.log('[JS] Tab audio connected to analyser');
        }

        // Video: display in background video element
        const videoTracks = tabStream.getVideoTracks();
        if (videoTracks.length > 0) {
          const videoEl = document.getElementById('tabVideo');
          videoEl.srcObject = new MediaStream(videoTracks);
          videoEl.play();
          videoEl.style.display = 'block';
          document.getElementById('tabOverlay').style.display = 'block';
          if (renderer && renderer.domElement) {
            renderer.domElement.style.mixBlendMode = 'screen';
          }
          console.log('[JS] Tab video overlay active');
        }

        // Handle stream end (user stops sharing via browser UI)
        tabStream.getTracks().forEach(track => {
          track.addEventListener('ended', stopTabCapture);
        });

        document.getElementById('cpSrcTab')?.classList.add('active');
        if (window.rubyOnTabToggle) window.rubyOnTabToggle(true);
        console.log('[JS] Tab capture started');
      } catch (error) {
        console.error('[JS] Tab capture error:', error);
        tabStream = null;
      }
    }

    // Stop tab capture and clean up
    function stopTabCapture() {
      if (tabStream) {
        tabStream.getTracks().forEach(t => t.stop());
        tabStream = null;
      }
      if (tabAudioSource) {
        tabAudioSource.disconnect();
        tabAudioSource = null;
      }
      if (tabAudioGain) {
        tabAudioGain.disconnect();
        tabAudioGain = null;
      }
      const videoEl = document.getElementById('tabVideo');
      if (videoEl) {
        videoEl.srcObject = null;
        videoEl.style.display = 'none';
      }
      const overlayEl = document.getElementById('tabOverlay');
      if (overlayEl) overlayEl.style.display = 'none';
      if (renderer && renderer.domElement) {
        renderer.domElement.style.mixBlendMode = 'normal';
      }
      document.getElementById('cpSrcTab')?.classList.remove('active');
      if (window.rubyOnTabToggle) window.rubyOnTabToggle(false);
      console.log('[JS] Tab capture stopped');
    }

    // Toggle tab capture on/off
    function toggleTabCapture() {
      if (tabStream) {
        stopTabCapture();
      } else {
        startTabCapture();
      }
    }

    // Start capturing video from camera
    async function startCameraCapture() {
      try {
        cameraStream = await navigator.mediaDevices.getUserMedia({ video: true });
        const videoEl = document.getElementById('tabVideo');
        videoEl.srcObject = new MediaStream(cameraStream.getVideoTracks());
        videoEl.play();
        videoEl.style.display = 'block';
        document.getElementById('tabOverlay').style.display = 'block';
        if (renderer && renderer.domElement) renderer.domElement.style.mixBlendMode = 'screen';
        updateAudioSourceButtons('camera');
        console.log('[JS] Camera capture started');
      } catch (error) {
        console.error('[JS] Camera capture error:', error);
        cameraStream = null;
      }
    }

    // Stop camera capture
    function stopCameraCapture() {
      if (cameraStream) { cameraStream.getTracks().forEach(t => t.stop()); cameraStream = null; }
      const videoEl = document.getElementById('tabVideo');
      if (videoEl) { videoEl.srcObject = null; videoEl.style.display = 'none'; }
      const overlayEl = document.getElementById('tabOverlay');
      if (overlayEl) overlayEl.style.display = 'none';
      if (renderer && renderer.domElement) renderer.domElement.style.mixBlendMode = 'normal';
      updateAudioSourceButtons('mic');
      console.log('[JS] Camera capture stopped');
    }

    // Toggle camera capture on/off
    function toggleCameraCapture() {
      if (cameraStream) { stopCameraCapture(); } else { startCameraCapture(); }
    }

    // Update audio source button active state (individual toggles)
    function updateAudioSourceButtons(source) {
      ['mic', 'camera', 'tab'].forEach(s => {
        const btn = document.getElementById('cpSrc' + s.charAt(0).toUpperCase() + s.slice(1));
        if (btn) btn.classList.toggle('active', s === source);
      });
    }

    // Show microphone device picker popup
    async function showMicDevicePicker() {
      // Request permission first so labels are available
      try { await navigator.mediaDevices.getUserMedia({ audio: true }); } catch (_e) {}
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices.filter(d => d.kind === 'audioinput');

      // Remove existing picker
      document.getElementById('micDevicePicker')?.remove();

      const picker = document.createElement('div');
      picker.id = 'micDevicePicker';
      picker.style.cssText = 'position:fixed;background:#1a1a1a;border:1px solid #555;border-radius:4px;z-index:2000;padding:4px;min-width:200px;';

      audioInputs.forEach((dev, i) => {
        const btn = document.createElement('button');
        btn.className = 'cp-btn';
        btn.style.cssText = 'display:block;width:100%;text-align:left;padding:4px 8px;font-size:10px;margin:1px 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;';
        btn.textContent = dev.label || ('Microphone ' + (i + 1));
        if (dev.deviceId === (micDeviceId || 'default') || (!micDeviceId && dev.deviceId === 'default')) {
          btn.style.color = '#0f0';
        }
        btn.addEventListener('click', async () => {
          picker.remove();
          micDeviceId = dev.deviceId;
          await reconnectMic(dev.deviceId);
        });
        picker.appendChild(btn);
      });

      // Position near Mic button
      const micBtn = document.getElementById('cpSrcMic');
      const rect = micBtn?.getBoundingClientRect();
      if (rect) {
        picker.style.top = (rect.bottom + 4) + 'px';
        picker.style.left = rect.left + 'px';
      }
      document.body.appendChild(picker);

      // Close on outside click
      setTimeout(() => {
        document.addEventListener('click', function closePicker(e) {
          if (!picker.contains(e.target)) {
            picker.remove();
            document.removeEventListener('click', closePicker);
          }
        });
      }, 0);
    }

    // Reconnect mic to a specific device
    async function reconnectMic(deviceId) {
      try {
        if (micGain) { micGain.disconnect(); micGain = null; }
        const constraints = { audio: deviceId ? { deviceId: { exact: deviceId } } : true };
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        const source = audioContext.createMediaStreamSource(stream);
        micGain = audioContext.createGain();
        micGain.gain.value = micMuted ? 0 : 1;
        source.connect(micGain);
        micGain.connect(analyser);
        document.getElementById('cpSrcMic')?.classList.add('active');
        console.log('[JS] Mic reconnected:', deviceId);
      } catch (error) {
        console.error('[JS] Mic reconnect error:', error);
      }
    }

    // Start camera mic audio (separate from camera video stream)
    async function startCamMic() {
      try {
        camMicStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
        camMicSource = audioContext.createMediaStreamSource(camMicStream);
        camMicGain = audioContext.createGain();
        camMicGain.gain.value = 1.0;
        camMicSource.connect(camMicGain);
        camMicGain.connect(analyser);
        document.getElementById('cpSrcCamera')?.classList.add('active');
        console.log('[JS] Cam Mic started');
      } catch (error) {
        console.error('[JS] Cam Mic error:', error);
        camMicStream = null;
      }
    }

    // Stop camera mic audio
    function stopCamMic() {
      if (camMicStream) { camMicStream.getTracks().forEach(t => t.stop()); camMicStream = null; }
      if (camMicSource) { camMicSource.disconnect(); camMicSource = null; }
      if (camMicGain) { camMicGain.disconnect(); camMicGain = null; }
      document.getElementById('cpSrcCamera')?.classList.remove('active');
      console.log('[JS] Cam Mic stopped');
    }

    // Toggle cam mic on/off
    function toggleCamMic() {
      if (camMicStream) { stopCamMic(); } else { startCamMic(); }
    }

    // Toggle mic source on/off
    function toggleMicSource() {
      if (micGain) {
        micGain.disconnect();
        micGain = null;
        document.getElementById('cpSrcMic')?.classList.remove('active');
        console.log('[JS] Mic source disconnected');
      } else {
        reconnectMic(micDeviceId);
      }
    }

    // BroadcastChannel for perf view sync
    let _perfChannel = null;

    function broadcastState() {
      if (!_perfChannel) return;
      const qs = window.location.search;
      _perfChannel.postMessage({ type: 'state', qs });
    }

    // Open performance view window (single/multi monitor)
    async function togglePerfView() {
      const perfUrl = window.location.origin + window.location.pathname + '?perf=1';
      let w = null;

      // Try Window Management API for external monitor placement
      if ('getScreenDetails' in window) {
        try {
          const screens = await window.getScreenDetails();
          const external = screens.screens.find(s => !s.isInternal) || screens.screens[1];
          if (external) {
            w = window.open(perfUrl, 'perf-view',
              'popup,left=' + external.availLeft + ',top=' + external.availTop +
              ',width=' + external.availWidth + ',height=' + external.availHeight);
          }
        } catch (e) {
          console.log('[JS] Window Management API not available, opening as popup');
        }
      }

      // Fallback: open as regular popup window (works on single monitor)
      if (!w) {
        w = window.open(perfUrl, 'perf-view', 'popup,width=1280,height=720');
      }

      if (w) {
        w.focus();  // Bring perf view to foreground so Ruby WASM initializes properly
        _perfChannel = new BroadcastChannel('visualizer-sync');
        setTimeout(() => broadcastState(), 2000);
        console.log('[JS] Perf view window opened');
      }
    }

    // Three.js Setup
    function initThree() {
      // Three.js モジュールが読み込まれるまで待機
      if (!window.THREE_READY) {
        console.log('[JS] Waiting for Three.js to load...');
        setTimeout(initThree, 100);
        return;
      }

      console.log('[JS] Initializing Three.js...');

      scene = new THREE.Scene();
      camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
      // Initialize camera target and position with spherical coordinates
      cameraTarget = new THREE.Vector3(0, 0, 0);
      updateCameraPosition();
      // Enable all layers for camera (Layer 0 for VRM, Layer 1 for particles/torus)
      camera.layers.enableAll();

      renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.setClearColor(0x000000, 0);
      document.body.appendChild(renderer.domElement);

      // If tab video is active, apply mix-blend-mode
      const tabVideo = document.getElementById('tabVideo');
      if (tabVideo && tabVideo.style.display === 'block') {
        renderer.domElement.style.mixBlendMode = 'screen';
        console.log('[JS] Applied mix-blend-mode: screen for tab video overlay');
      }

      // Post-processing setup
      composer = new EffectComposer(renderer);

      renderPass = new RenderPass(scene, camera);
      composer.addPass(renderPass);

      bloomPass = new UnrealBloomPass(
        new THREE.Vector2(window.innerWidth, window.innerHeight),
        1.5,   // Bloom strength
        0.4,   // Bloom radius
        0.0    // Threshold 0.0 = 全体を輝かせる
      );
      composer.addPass(bloomPass);

      // OutputPass を追加（最終出力用）
      const outputPass = new OutputPass();
      composer.addPass(outputPass);

      // Particle system
      const particleCount = 3000;
      const geometry = new THREE.BufferGeometry();
      const positions = new Float32Array(particleCount * 3);
      const colors = new Float32Array(particleCount * 3);

      for (let i = 0; i < particleCount; i++) {
        positions[i * 3] = (Math.random() - 0.5) * 10;
        positions[i * 3 + 1] = (Math.random() - 0.5) * 10;
        positions[i * 3 + 2] = (Math.random() - 0.5) * 10;
        colors[i * 3] = 0.3;      // dim gray (グレースケール起動)
        colors[i * 3 + 1] = 0.3;
        colors[i * 3 + 2] = 0.3;
      }

      geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
      geometry.setAttribute('color', new THREE.BufferAttribute(colors, 3));

      const material = new THREE.PointsMaterial({
        size: 0.05,
        vertexColors: true,
        transparent: true,
        opacity: 0.8,
        blending: THREE.AdditiveBlending
      });

      particleSystem = new THREE.Points(geometry, material);
      // particleSystem.layers.set(BLOOM_LAYER);  // DISABLED: Enable bloom for particles
      scene.add(particleSystem);

      // Morphing geometry (torus) - ポリゴン削減で FPS 改善（32,64 → 24,32）
      const torusGeometry = new THREE.TorusGeometry(1, 0.4, 12, 16);
      const torusMaterial = new THREE.MeshStandardMaterial({
        color: 0x4d4d4d,  // dim gray (グレースケール起動)
        wireframe: true,
        transparent: true,
        opacity: 0.6,
        emissive: 0xffffff,  // white for uniform glow
        emissiveIntensity: 0.3,  // initial intensity
        metalness: 0.0,
        roughness: 1.0
      });
      geometryMesh = new THREE.Mesh(torusGeometry, torusMaterial);
      // geometryMesh.layers.set(BLOOM_LAYER);  // DISABLED: Enable bloom for torus
      scene.add(geometryMesh);

      // Initialize Selective Bloom materials
      bloomLayer = new THREE.Layers();
      bloomLayer.set(BLOOM_LAYER);
      darkMaterial = new THREE.MeshBasicMaterial({ color: 'black' });

      console.log('[JS] Three.js initialized successfully');

      // Setup keyboard controls for camera rotation
      setupCameraControls();
    }

    // Update camera position using spherical coordinates
    function updateCameraPosition() {
      const x = cameraRadius * Math.cos(cameraPhi) * Math.sin(cameraTheta);
      const y = cameraRadius * Math.sin(cameraPhi);
      const z = cameraRadius * Math.cos(cameraPhi) * Math.cos(cameraTheta);
      camera.position.set(cameraTarget.x + x, cameraTarget.y + y, cameraTarget.z + z);
      camera.lookAt(cameraTarget);
    }

    // Setup keyboard controls for camera rotation
    function setupCameraControls() {
      document.addEventListener('keydown', (event) => {
        const rotationStep = Math.PI / 18;  // 10 degrees

        switch(event.key.toLowerCase()) {
          case 'd':  // Rotate left
            cameraTheta -= rotationStep;
            updateCameraPosition();
            break;
          case 'f':  // Rotate right
            cameraTheta += rotationStep;
            updateCameraPosition();
            break;
          case 'e':  // Rotate up
            cameraPhi = Math.min(cameraPhi + rotationStep, Math.PI / 2 - 0.01);  // Clamp to avoid gimbal lock
            updateCameraPosition();
            break;
          case 'c':  // Rotate down
            cameraPhi = Math.max(cameraPhi - rotationStep, -Math.PI / 2 + 0.01);  // Clamp to avoid gimbal lock
            updateCameraPosition();
            break;
        }
      });

      console.log('[JS] Camera controls initialized (d/f: rotate left/right, e/c: rotate up/down)');
    }

    // Unload current VRM from scene
    function unloadVRM() {
      if (!currentVRM) return;
      scene.remove(currentVRM.scene);
      currentVRM = null;
      window.currentVRM = null;
      if (geometryMesh) geometryMesh.position.z = 0;
      document.getElementById('cpLoadVrmBtn')?.classList.remove('active');
      console.log('[JS] VRM unloaded');
    }

    // Toggle VRM: if loaded → unload; if not loaded → open file picker
    function triggerVRMFileLoad() {
      if (currentVRM) {
        unloadVRM();
        return;
      }
      const input = document.getElementById('vrmFileInput');
      input.value = '';  // Reset so same file can be reloaded
      input.onchange = async (event) => {
        const file = event.target.files[0];
        if (file) {
          await loadVRMFile(file);
          camera.position.z = 1.5;
          document.getElementById('cpLoadVrmBtn')?.classList.add('active');
          console.log('[JS] VRM loaded:', file.name);
        }
      };
      input.click();
    }

    // Debounced URL update using rubySnapshotEncode
    let _urlUpdateTimer = null;
    function scheduleURLUpdate() {
      if (!window.rubySnapshotEncode) return;
      clearTimeout(_urlUpdateTimer);
      _urlUpdateTimer = setTimeout(() => {
        const qs = String(window.rubySnapshotEncode(
          cameraRadius,
          Math.round(cameraTheta * 180 / Math.PI),
          Math.round(cameraPhi * 180 / Math.PI)
        )) + '&ov=' + capOverlayOpacity.toFixed(2) + '&vv=' + capVideoOpacity.toFixed(2);
        history.replaceState(null, '', window.location.pathname + qs);
        broadcastState();
      }, 500);
    }

    // Load VRM from File object
    async function loadVRMFile(file) {
      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onload = (event) => {
          const arrayBuffer = event.target.result;
          const loader = new GLTFLoader();
          loader.register((parser) => new VRMLoaderPlugin(parser));

          loader.parse(arrayBuffer, '', (gltf) => {
            currentVRM = gltf.userData.vrm;
            window.currentVRM = currentVRM;  // Expose to global scope for Ruby access

            VRMUtils.removeUnnecessaryVertices(gltf.scene);
            VRMUtils.removeUnnecessaryJoints(gltf.scene);

            // Position the VRM model at center, slightly lower, and closer to camera
            currentVRM.scene.position.set(0, -1.2, 0.3);

            // Scale up the model for better visibility (2x)
            currentVRM.scene.scale.set(2.0, 2.0, 2.0);

            scene.add(currentVRM.scene);

            // Add lights for VRM materials (does not affect unlit particles/torus)
            const dirLight = new THREE.DirectionalLight(0xffffff, 1.0);
            dirLight.position.set(1, 2, 1);
            scene.add(dirLight);
            const ambLight = new THREE.AmbientLight(0x666666);
            scene.add(ambLight);

            // Move torus behind VRM model (background)
            if (geometryMesh) {
              geometryMesh.position.z = -2.0;
            }

            // Initialize VRM materials with emissive for bloom
            // (Ruby will control the intensity dynamically)
            // Use material's base color for emissive to make all parts glow naturally
            // VRM材質はデフォルトのまま（ローダーの設定を尊重）
            // updateVRMMaterial で emissiveIntensity のみ更新する

            console.log('[JS] VRM model loaded successfully');
            resolve();
          }, (error) => {
            console.error('[JS] VRM load error:', error);
            reject(error);
          });
        };
        reader.onerror = (err) => reject(err);
        reader.readAsArrayBuffer(file);
      });
    }

    // Update VRM bones from Ruby dance data
    window.updateVRM = function(rotations, hipsY, blink, mouthV, mouthH) {
      if (!currentVRM) return;

      const humanoid = currentVRM.humanoid;
      const rotArray = Array.from(rotations || []);
      const hipsPositionY = Number(hipsY) || 0;
      const blinkValue = Number(blink) || 0;
      const mouthOpenVertical = Number(mouthV) || 0;
      const mouthOpenHorizontal = Number(mouthH) || 0;

      for (let i = 0; i < VRM_BONE_ORDER.length; i++) {
        const boneName = VRM_BONE_ORDER[i];
        const bone = humanoid.getNormalizedBoneNode(boneName);
        if (bone) {
          const rx = Number(rotArray[i * 3]) || 0;
          const ry = Number(rotArray[i * 3 + 1]) || 0;
          const rz = Number(rotArray[i * 3 + 2]) || 0;
          bone.rotation.set(rx, ry, rz);

          // Hips position (bounce) - use set, not accumulate
          if (boneName === 'hips') {
            bone.position.y = hipsPositionY;
          }
        }
      }

      // Update expressions
      const expressionManager = currentVRM.expressionManager;
      if (expressionManager) {
        // Blink
        expressionManager.setValue('blink', blinkValue);
        expressionManager.setValue('blinkLeft', blinkValue);
        expressionManager.setValue('blinkRight', blinkValue);

        // Mouth (vertical = aa, horizontal = ee)
        expressionManager.setValue('aa', mouthOpenVertical);
        expressionManager.setValue('ee', mouthOpenHorizontal);
      }
    };

    // Update VRM material emissive for bloom effect
    // Only update intensity, preserve the base color set during initialization
    window.updateVRMMaterial = function(intensity, color) {
      if (!currentVRM) {
        console.warn('[JS] updateVRMMaterial called but currentVRM is null');
        return;
      }

      const emissiveIntensity = Number(intensity) || 1.0;

      // Debug: log every 60 frames (assuming 60fps)
      let materialCount = 0;
      let updatedCount = 0;

      currentVRM.scene.traverse((node) => {
        if (node.isMesh && node.material) {
          const materials = Array.isArray(node.material) ? node.material : [node.material];
          materials.forEach((mat) => {
            materialCount++;
            if (mat.emissive && mat.emissiveIntensity !== undefined) {
              // Only update intensity, keep the color (which was copied from mat.color)
              mat.emissiveIntensity = emissiveIntensity;
              mat.needsUpdate = true;
              updatedCount++;
            }
          });
        }
      });

      if (frameCount % 60 === 0) {
        console.log('[DEBUG JS VRM] intensity=' + emissiveIntensity.toFixed(2) +
                    ' materials=' + materialCount + ' updated=' + updatedCount);
      }
    };

    // Update functions called from Ruby
    window.updateParticles = function(positions, colors, avgSize, avgOpacity) {
      if (!particleSystem) {
        console.warn('[JS] particleSystem is not initialized');
        return;
      }

      const posAttr = particleSystem.geometry.attributes.position;
      const colAttr = particleSystem.geometry.attributes.color;

      if (!posAttr || !colAttr) {
        console.warn('[JS] Attributes not found');
        return;
      }

      // Convert to numbers if needed
      const posArray = typeof positions === 'number' ? [positions] : Array.from(positions || []);
      const colArray = typeof colors === 'number' ? [colors] : Array.from(colors || []);

      if (posArray.length > 0 && colArray.length > 0) {
        for (let i = 0; i < posArray.length && i < posAttr.array.length; i++) {
          posAttr.array[i] = Number(posArray[i]) || 0;
        }
        for (let i = 0; i < colArray.length && i < colAttr.array.length; i++) {
          colAttr.array[i] = Number(colArray[i]) || 0;
        }

        posAttr.needsUpdate = true;
        colAttr.needsUpdate = true;

        // サイズと透明度の動的更新（Ruby で計算済みの平均値を使用）
        if (particleSystem.material) {
          particleSystem.material.size = Number(avgSize) || 0.05;
          particleSystem.material.opacity = Math.max(0.3, Math.min(1.0, Number(avgOpacity) || 0.8));
        }
      }
    };

    window.updateGeometry = function(scale, rotation, emissiveIntensity, color) {
      if (!geometryMesh) {
        console.warn('[JS] geometryMesh is not initialized');
        return;
      }

      const scaleNum = Number(scale) || 1.0;
      geometryMesh.scale.set(scaleNum, scaleNum, scaleNum);

      if (rotation && Array.isArray(rotation) && rotation.length >= 3) {
        geometryMesh.rotation.x = Number(rotation[0]) || 0;
        geometryMesh.rotation.y = Number(rotation[1]) || 0;
        geometryMesh.rotation.z = Number(rotation[2]) || 0;
      }

      // Ruby から渡された色を使用（新規追加）
      if (color && Array.isArray(color) && color.length >= 3 && geometryMesh.material) {
        const r = Number(color[0]) || 0;
        const g = Number(color[1]) || 0;
        const b = Number(color[2]) || 0;

        // Base color
        if (geometryMesh.material.color) {
          geometryMesh.material.color.setRGB(r, g, b);
        }

        // Emissive intensity (using emissiveIntensity property like VRM)
        if (emissiveIntensity !== undefined && geometryMesh.material.emissiveIntensity !== undefined) {
          const intensity = Number(emissiveIntensity) || 0;
          geometryMesh.material.emissiveIntensity = intensity;
          geometryMesh.material.needsUpdate = true;
        }
      }
    };

    window.updateBloom = function(strength, threshold) {
      if (!bloomPass) {
        console.warn('[JS] bloomPass is not initialized');
        return;
      }

      bloomPass.strength = strength !== undefined ? Number(strength) : 1.5;
      bloomPass.threshold = threshold !== undefined ? Number(threshold) : 0.0;

      // Debug: log every 120 frames
      if (frameCount % 120 === 0) {
        console.log('[DEBUG BLOOM] strength=' + bloomPass.strength.toFixed(2) +
                    ' threshold=' + bloomPass.threshold.toFixed(2));
      }
    };

    window.updateCamera = function(position, shake) {
      if (!camera) {
        console.warn('[JS] camera is not initialized');
        return;
      }

      const pos = Array.isArray(position) ? position : [0, 0, 5];
      const shk = Array.isArray(shake) ? shake : [0, 0, 0];

      camera.position.x = Number(pos[0]) + Number(shk[0]);
      camera.position.y = Number(pos[1]) + Number(shk[1]);
      camera.position.z = Number(pos[2]) + Number(shk[2]);
    };

    window.updateParticleRotation = function(rotation) {
      if (!particleSystem) {
        console.warn('[JS] particleSystem is not initialized');
        return;
      }

      if (rotation && Array.isArray(rotation) && rotation.length >= 3) {
        particleSystem.rotation.x = Number(rotation[0]) || 0;
        particleSystem.rotation.y = Number(rotation[1]) || 0;
        particleSystem.rotation.z = Number(rotation[2]) || 0;
      }
    };

    // Selective Bloom helper functions
    function darkenNonBloomed(obj) {
      if (obj.isMesh && bloomLayer.test(obj.layers) === false) {
        materials[obj.uuid] = obj.material;
        obj.material = darkMaterial;
      }
    }

    function restoreMaterial(obj) {
      if (materials[obj.uuid]) {
        obj.material = materials[obj.uuid];
        delete materials[obj.uuid];
      }
    }

    // Animation loop (thin: data extraction + Ruby callback + render)
    function animate() {
      requestAnimationFrame(animate);

      // Delta time for VRM
      const now = Date.now();
      const deltaTime = (now - animLastTime) / 1000;
      animLastTime = now;
      window._animDeltaTime = deltaTime;

      // Extract frequency data and call Ruby (Ruby handles FPS, debug, BPM)
      // analyser may be null in perf view, but Ruby still needs to be called for scene updates
      if (window.rubyUpdateVisuals) {
        try {
          if (analyser) analyser.getByteFrequencyData(dataArray);
          window.rubyUpdateVisuals(Array.from(dataArray || []), now);
        } catch (error) {
          console.error('[JS] Error calling Ruby update:', error);
        }
      }

      // Display update: read Ruby-formatted strings
      frameCount++;
      if (frameCount % 15 === 0) {  // Update DOM every ~15 frames
        if (window.fpsText) {
          document.getElementById('fpsCounter').textContent = window.fpsText;
        }
        if (window.debugInfoText) {
          document.getElementById('debugInfo').textContent = window.debugInfoText;
        }

        let paramText = window.paramInfoText || '';
        if (camera) {
          paramText += `  |  Cam: (${camera.position.x.toFixed(1)}, ${camera.position.y.toFixed(1)}, ${camera.position.z.toFixed(1)})`;
        }
        if (window.vrmDebugText) {
          paramText += `  |  ${window.vrmDebugText}`;
        }
        if (paramText) {
          document.getElementById('paramInfo').textContent = paramText;
        }
        if (window.keyGuideText) {
          document.getElementById('keyGuide').textContent = window.keyGuideText;
        }
      }

      // VRM spring bones update
      if (currentVRM) currentVRM.update(deltaTime);

      // Render
      if (composer) composer.render();
    }

    // Load Ruby code from embedded script tags
    async function loadRubyCode() {
      const rubyBlocks = document.querySelectorAll('script[type="text/ruby"]');
      for (const block of rubyBlocks) {
        const code = block.textContent;
        try {
          if (window.rubyVM) {
            window.rubyVM.eval(code);
            console.log(`[JS] Loaded Ruby code block: ${block.id}`);
          }
        } catch (error) {
          console.error(`Failed to load Ruby code block ${block.id}:`, error);
          throw error;
        }
      }
    }

    function updateLoadingStatus(message) {
      const el = document.getElementById('loadingStatus');
      if (el) {
        el.textContent = message;
      }
      console.log('[JS] ' + message);
    }

    // Wait for Ruby WASM to finish loading (polls for rubyUpdateVisuals)
    function waitForRubyReady() {
      return new Promise(resolve => {
        (function check() {
          window.rubyUpdateVisuals ? resolve() : setTimeout(check, 100);
        })();
      });
    }

    // Initialize everything (auto-start flow)
    async function init() {
      try {
        // Phase 1: Wait for Ruby WASM to finish loading
        updateLoadingStatus('Loading Ruby WASM...');
        await waitForRubyReady();
        console.log('[JS] Ruby WASM ready');

        // Phase 2: Initialize Three.js and start animation immediately
        updateLoadingStatus('Initializing Three.js...');
        initThree();

        updateLoadingStatus('Starting preview...');
        animate();

        // Phase 3: Hide loading
        document.getElementById('loading').style.display = 'none';

        if (IS_PERF_VIEW) {
          // Performance view: no control panel, no audio, BroadcastChannel receiver
          console.log('[JS] Performance view mode active');
          // Hide control panel trigger, hide VJ prompt input
          document.getElementById('controlPanel').style.display = 'none';
          const vjInputEl = document.getElementById('vjPromptInput');
          if (vjInputEl) vjInputEl.style.display = 'none';
          const vjPromptEl = document.getElementById('vjPrompt');
          if (vjPromptEl) vjPromptEl.style.pointerEvents = 'none';

          // BroadcastChannel receiver
          _perfChannel = new BroadcastChannel('visualizer-sync');
          _perfChannel.addEventListener('message', (e) => {
            if (e.data.type === 'state' && window.rubySnapshotApply) {
              const _snapRaw = String(window.rubySnapshotApply(e.data.qs) || '');
              if (_snapRaw) {
                try {
                  const _cam = JSON.parse(_snapRaw);
                  SLIDER_GROUPS['Camera'][0].setter(_cam.cr);
                  SLIDER_GROUPS['Camera'][1].setter(_cam.cth);
                  SLIDER_GROUPS['Camera'][2].setter(_cam.cph);
                } catch (_e) {}
              }
              const _p = new URLSearchParams(e.data.qs);
              const _ov = parseFloat(_p.get('ov'));
              const _vv = parseFloat(_p.get('vv'));
              if (!isNaN(_ov)) { capOverlayOpacity = _ov; document.getElementById('tabOverlay').style.opacity = _ov; }
              if (!isNaN(_vv)) { capVideoOpacity = _vv; document.getElementById('tabVideo').style.opacity = _vv; }
            }
            if (e.data.type === 'vj_log' && e.data.cmd) {
              const vjResult = document.getElementById('vjPromptResult');
              if (vjResult) vjResult.textContent = '> ' + e.data.cmd + (e.data.result ? ' → ' + e.data.result : '');
            }
          });
          console.log('[JS] BroadcastChannel receiver started');
          return;
        }

        // Normal mode: show control panel
        buildControlPanel();
        document.getElementById('controlPanel').classList.add('active');
        controlPanelOpen = true;

        // Apply URL snapshot before audio init (restores Ruby params + camera)
        const _snapRaw = String(window.rubySnapshotApply?.(window.location.search) || '');
        if (_snapRaw) {
          const _cam = JSON.parse(_snapRaw);
          SLIDER_GROUPS['Camera'][0].setter(_cam.cr);
          SLIDER_GROUPS['Camera'][1].setter(_cam.cth);
          SLIDER_GROUPS['Camera'][2].setter(_cam.cph);
          syncControlPanelValues();
        }

        // Apply ov/vv from URL and sync slider UI
        const _urlParams = new URLSearchParams(window.location.search);
        const _ov = parseFloat(_urlParams.get('ov'));
        const _vv = parseFloat(_urlParams.get('vv'));
        if (!isNaN(_ov)) {
          capOverlayOpacity = _ov;
          document.getElementById('tabOverlay').style.opacity = _ov;
          const _ovSlider = document.getElementById('cpSlider_cap_overlay_opacity');
          const _ovVal = document.getElementById('cpVal_cap_overlay_opacity');
          if (_ovSlider) _ovSlider.value = _ov;
          if (_ovVal) _ovVal.textContent = _ov.toFixed(2);
        }
        if (!isNaN(_vv)) {
          capVideoOpacity = _vv;
          document.getElementById('tabVideo').style.opacity = _vv;
          const _vvSlider = document.getElementById('cpSlider_cap_video_opacity');
          const _vvVal = document.getElementById('cpVal_cap_video_opacity');
          if (_vvSlider) _vvSlider.value = _vv;
          if (_vvVal) _vvVal.textContent = _vv.toFixed(2);
        }

        console.log('[JS] Preview started with control panel');

        // Phase 4: Start audio (VRM loaded later via Controls or Alt+V)
        await initAudio().catch(error => {
          console.warn('[JS] Audio init failed (will retry on user click):', error.message);
        });
        console.log('[JS] Continuing without VRM (use Controls or Alt+V to load)');
      } catch (error) {
        console.error('[JS] Initialization error:', error);
        updateLoadingStatus('Error: ' + error.message);
      }
    }

    // AudioContext の suspended 状態をユーザー操作で解除するフォールバック
    document.addEventListener('click', function resumeAudio() {
      if (audioContext && audioContext.state === 'suspended') {
        audioContext.resume().then(function() {
          console.log('[JS] AudioContext resumed by user click, state:', audioContext.state);
        });
      }
      document.removeEventListener('click', resumeAudio);
    });

    // VJ Pad prompt management
    const vjPrompt = document.getElementById('vjPrompt');
    const vjInput = document.getElementById('vjPromptInput');
    const vjResult = document.getElementById('vjPromptResult');
    const vjHistory = [];
    let vjHistoryIdx = -1;
    let vjPromptOpen = false;

    function vjPromptToggle() {
      vjPromptOpen = !vjPromptOpen;
      if (vjPromptOpen) {
        vjPrompt.classList.add('active');
        vjInput.value = '';
        vjResult.textContent = '';
        vjResult.className = '';
        vjHistoryIdx = -1;
        vjInput.focus();
      } else {
        vjPrompt.classList.remove('active');
        vjInput.blur();
      }
    }

    function vjPromptExec() {
      const cmd = vjInput.value.trim();
      if (!cmd) return;
      vjHistory.unshift(cmd);
      if (vjHistory.length > 50) vjHistory.pop();
      vjHistoryIdx = -1;
      let result = '';
      if (window.rubyExecPrompt) {
        try { result = window.rubyExecPrompt(cmd); } catch (e) { result = 'ERR: ' + e.message; }
      } else {
        result = 'ERR: Ruby VM not ready';
      }
      const isErr = typeof result === 'string' && result.startsWith('ERR:');
      vjResult.textContent = result || '';
      vjResult.className = isErr ? 'error' : '';
      vjInput.value = '';
      if (_syncChannel) _syncChannel.postMessage({ type: 'vj_log', cmd, result: String(result || '') });
      // Auto-clear result after 3s
      clearTimeout(vjResult._clearTimer);
      vjResult._clearTimer = setTimeout(() => {
        vjResult.textContent = '';
        vjResult.className = '';
      }, 3000);
    }

    // Prompt input key handling
    vjInput.addEventListener('keydown', function(e) {
      e.stopPropagation();
      if (e.key === 'Enter') { vjPromptExec(); }
      else if (e.key === 'Escape' || e.key === '`') { e.preventDefault(); vjPromptToggle(); }
      else if (e.key === 'ArrowUp') {
        e.preventDefault();
        if (vjHistory.length > 0 && vjHistoryIdx < vjHistory.length - 1) {
          vjHistoryIdx++;
          vjInput.value = vjHistory[vjHistoryIdx];
        }
      } else if (e.key === 'ArrowDown') {
        e.preventDefault();
        if (vjHistoryIdx > 0) { vjHistoryIdx--; vjInput.value = vjHistory[vjHistoryIdx]; }
        else { vjHistoryIdx = -1; vjInput.value = ''; }
      }
    });

    // Keyboard handler: Ruby handles config/color keys, JS handles camera (WebGL direct)
    window.addEventListener('keydown', function(event) {
      // When prompt is open, restore focus if lost, then let input handler process the key
      if (vjPromptOpen) {
        if (document.activeElement !== vjInput) {
          vjInput.focus();
        }
        return;
      }

      const key = event.key;

      // Backtick toggles VJ Pad prompt
      if (key === '`') { event.preventDefault(); vjPromptToggle(); return; }

      // Control panel toggle (disabled in perf view)
      if (key === 'p' && !IS_PERF_VIEW) { toggleControlPanel(); return; }

      // Audio input controls (must stay in JS - direct Web Audio manipulation)
      if (key === 'm') { toggleMic(); return; }

      // VRM / Tab capture / Camera: Alt modifier required to prevent accidental trigger during VJ play
      if (event.altKey && key === 't') { toggleTabCapture(); return; }
      if (event.altKey && key === 'v') { triggerVRMFileLoad(); return; }
      if (event.altKey && key === 'c') { toggleCameraCapture(); return; }

      // Camera position controls (must stay in JS - direct Three.js manipulation)
      if ('aswxqz'.includes(key) && camera) {
        const step = 0.5;
        if (key === 'a') camera.position.x -= step;
        else if (key === 's') camera.position.x += step;
        else if (key === 'w') camera.position.y += step;
        else if (key === 'x') camera.position.y -= step;
        else if (key === 'q') camera.position.z += step;
        else if (key === 'z') camera.position.z -= step;
        return;
      }

      // All other keys dispatched to Ruby master handler
      if (window.rubyHandleKey) {
        try {
          window.rubyHandleKey(key);
          scheduleURLUpdate();
        } catch (error) {
          console.error('[JS] Error calling rubyHandleKey:', error);
        }
      }
    });

    console.log('[JS] Keyboard: Ruby handles config keys, JS handles camera (a/s/w/x/q/z, d/f/e/c), backtick(`) opens VJ Pad');

    // DevTool console interface for dynamic config changes
    // Usage: rubyConfig.set('sensitivity', 2.5) / .get('sensitivity') / .list() / .reset()
    window.rubyConfig = {
      set: (key, value) => window.rubyConfigSet?.(key, value) ?? 'Ruby VM not ready',
      get: (key) => window.rubyConfigGet?.(key) ?? 'Ruby VM not ready',
      list: () => window.rubyConfigList?.() ?? 'Ruby VM not ready',
      reset: () => window.rubyConfigReset?.() ?? 'Ruby VM not ready',
      help: () => console.log('Usage: rubyConfig.set(key, value) | .get(key) | .list() | .reset()')
    };

    // === Control Panel ===
    let controlPanelOpen = false;

    // Slider definitions (mirrors VisualizerPolicy::MUTABLE_KEYS)
    const SLIDER_GROUPS = {
      'Master': [
        { key: 'sensitivity', label: 'Sensitivity', min: 0.05, max: 10.0, step: 0.05, default: 1.0 },
      ],
      'Bloom': [
        { key: 'bloom_base_strength', label: 'Base Strength', min: 0.0, max: 5.0, step: 0.1, default: 1.5 },
        { key: 'max_bloom', label: 'Max (Cap)', min: 0.0, max: 10.0, step: 0.1, default: 4.5 },
        { key: 'bloom_energy_scale', label: 'Energy Scale', min: 0.0, max: 5.0, step: 0.1, default: 2.5 },
        { key: 'bloom_impulse_scale', label: 'Impulse Scale', min: 0.0, max: 3.0, step: 0.1, default: 1.5 },
      ],
      'Particles': [
        { key: 'particle_explosion_base_prob', label: 'Explosion Prob.', min: 0.0, max: 1.0, step: 0.01, default: 0.20 },
        { key: 'particle_explosion_energy_scale', label: 'Energy Scale', min: 0.0, max: 2.0, step: 0.01, default: 0.50 },
        { key: 'particle_explosion_force_scale', label: 'Force Scale', min: 0.0, max: 2.0, step: 0.01, default: 0.55 },
        { key: 'particle_friction', label: 'Friction', min: 0.50, max: 0.99, step: 0.01, default: 0.86 },
      ],
      'Rendering': [
        { key: 'max_lightness', label: 'Max Lightness', min: 0, max: 255, step: 1, default: 255 },
        { key: 'max_emissive', label: 'Max Emissive', min: 0.0, max: 10.0, step: 0.1, default: 2.0 },
      ],
      'Audio': [
        { key: 'visual_smoothing', label: 'Visual Smoothing', min: 0.0, max: 0.99, step: 0.01, default: 0.70 },
        { key: 'impulse_decay', label: 'Impulse Decay', min: 0.50, max: 0.99, step: 0.01, default: 0.82 },
      ],
      'Camera': [
        { key: 'camera_radius', label: 'Distance', min: 1, max: 20, step: 0.1, default: 5,
          setter: v => { cameraRadius = v; if (cameraTarget) updateCameraPosition(); },
          getter: () => parseFloat(cameraRadius.toFixed(1)) },
        { key: 'camera_theta', label: 'H.Rotation', min: -180, max: 180, step: 5, default: 0,
          setter: v => { cameraTheta = v * Math.PI / 180; if (cameraTarget) updateCameraPosition(); },
          getter: () => Math.round(cameraTheta * 180 / Math.PI) },
        { key: 'camera_phi', label: 'V.Rotation', min: -80, max: 80, step: 5, default: 0,
          setter: v => { cameraPhi = v * Math.PI / 180; if (cameraTarget) updateCameraPosition(); },
          getter: () => Math.round(cameraPhi * 180 / Math.PI) },
      ],
      'Capture': [
        { key: 'cap_overlay_opacity', label: 'Overlay Opacity', min: 0, max: 1, step: 0.01, default: 0.5,
          setter: v => { capOverlayOpacity = v; document.getElementById('tabOverlay').style.opacity = v; },
          getter: () => capOverlayOpacity },
        { key: 'cap_video_opacity', label: 'Video Opacity', min: 0, max: 1, step: 0.01, default: 1.0,
          setter: v => { capVideoOpacity = v; document.getElementById('tabVideo').style.opacity = v; },
          getter: () => capVideoOpacity },
      ],
    };

    function initHueWheel() {
      const canvas = document.getElementById('hueWheel');
      if (!canvas) return;
      const ctx = canvas.getContext('2d');
      const cx = canvas.width / 2;
      const cy = canvas.height / 2;
      const outerR = 56;
      const innerR = 34;

      function drawWheel(currentHue) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        // Draw hue ring
        for (let deg = 0; deg < 360; deg++) {
          const startAngle = (deg - 90) * Math.PI / 180;
          const endAngle = (deg - 89) * Math.PI / 180;
          ctx.beginPath();
          ctx.arc(cx, cy, (outerR + innerR) / 2, startAngle, endAngle);
          ctx.lineWidth = outerR - innerR;
          ctx.strokeStyle = `hsl(${deg},100%,50%)`;
          ctx.stroke();
        }
        // Draw indicator dot at current hue
        const angle = (currentHue - 90) * Math.PI / 180;
        const dotR = (outerR + innerR) / 2;
        const dx = cx + dotR * Math.cos(angle);
        const dy = cy + dotR * Math.sin(angle);
        ctx.beginPath();
        ctx.arc(dx, dy, 5, 0, Math.PI * 2);
        ctx.fillStyle = '#fff';
        ctx.fill();
        ctx.strokeStyle = '#000';
        ctx.lineWidth = 1.5;
        ctx.stroke();
      }

      // Get current hue from Ruby and draw
      function getCurrentHue() {
        if (!window.rubyExecPrompt) return 0;
        try {
          const result = window.rubyExecPrompt('h');
          const match = String(result).match(/[\d.]+/);
          return match ? parseFloat(match[0]) : 0;
        } catch (e) { return 0; }
      }

      let currentHue = getCurrentHue();
      drawWheel(currentHue);
      document.getElementById('hueValueDisplay').textContent = currentHue.toFixed(1) + '°';

      // Helper: update hue wheel display to given value
      function syncWheelTo(hue) {
        currentHue = hue;
        drawWheel(currentHue);
        document.getElementById('hueValueDisplay').textContent = hue.toFixed(1) + '°';
      }

      // Helper: restore saturation from 0 when switching to color mode
      function restoreSatIfZero() {
        const curSat = window.rubyConfigGet?.('max_saturation') || 0;
        if (curSat === 0) {
          if (window.rubyConfigSet) window.rubyConfigSet('max_saturation', 100);
          const s = document.getElementById('cpSlider_max_saturation');
          const v = document.getElementById('cpVal_max_saturation');
          if (s) s.value = 100;
          if (v) v.textContent = '100';
        }
      }

      // Click handler: calculate angle from click position
      canvas.addEventListener('click', function(e) {
        const rect = canvas.getBoundingClientRect();
        const x = e.clientX - rect.left - cx;
        const y = e.clientY - rect.top - cy;
        const dist = Math.sqrt(x * x + y * y);
        if (dist < innerR || dist > outerR) return;  // Only respond in ring area
        let angle = Math.atan2(y, x) * 180 / Math.PI + 90;
        if (angle < 0) angle += 360;
        if (angle >= 360) angle -= 360;
        const hue = Math.round(angle);
        if (window.rubyExecPrompt) {
          // If in Gray mode, auto-switch to Red (user is picking a color)
          const modeResult = String(window.rubyExecPrompt('c'));
          if (modeResult.includes('gray')) {
            window.rubyExecPrompt('c 1');
            restoreSatIfZero();
          }
          window.rubyExecPrompt('h ' + hue);
        }
        syncWheelTo(hue);
        scheduleURLUpdate();
      });

      // Brightness and Saturation sliders (wired to rubyConfigSet/Get)
      const colorSliderDefs = [
        { id: 'max_brightness', decimals: 0 },
        { id: 'max_saturation', decimals: 0 },
      ];
      colorSliderDefs.forEach(({ id, decimals }) => {
        const slider = document.getElementById('cpSlider_' + id);
        const valueEl = document.getElementById('cpVal_' + id);
        if (!slider || !valueEl) return;
        // Sync initial value from Ruby
        const cur = window.rubyConfigGet?.(id);
        if (cur !== undefined && typeof cur === 'number') {
          slider.value = cur;
          valueEl.textContent = cur.toFixed(decimals);
        }
        slider.addEventListener('input', function() {
          const v = Number(this.value);
          valueEl.textContent = v.toFixed(decimals);
          if (window.rubyConfigSet) window.rubyConfigSet(id, v);
          // Saturation = 0: auto-switch to Gray mode + sync wheel to 0°
          if (id === 'max_saturation' && v === 0 && window.rubyExecPrompt) {
            window.rubyExecPrompt('c 0');
            syncWheelTo(0);
          }
          scheduleURLUpdate();
        });
        slider.addEventListener('keydown', function(e) { e.stopPropagation(); });
      });

      // Mode buttons (c 0/1/2/3) with Saturation slider sync
      const modes = [
        { label: 'Gray', cmd: 'c 0', isGray: true },
        { label: 'Red',  cmd: 'c 1', isGray: false },
        { label: 'Green', cmd: 'c 2', isGray: false },
        { label: 'Blue', cmd: 'c 3', isGray: false },
      ];
      const modeContainer = document.getElementById('colorModeButtons');
      if (modeContainer) {
        modes.forEach(m => {
          const btn = document.createElement('button');
          btn.className = 'cp-btn';
          btn.textContent = m.label;
          btn.style.flex = '0 0 auto';
          btn.style.padding = '3px 6px';
          btn.style.fontSize = '10px';
          btn.addEventListener('click', () => {
            if (window.rubyExecPrompt) window.rubyExecPrompt(m.cmd);
            const satSlider = document.getElementById('cpSlider_max_saturation');
            const satVal = document.getElementById('cpVal_max_saturation');
            if (m.isGray) {
              // Gray: set saturation to 0 + sync wheel to 0°
              if (window.rubyConfigSet) window.rubyConfigSet('max_saturation', 0);
              if (satSlider) satSlider.value = 0;
              if (satVal) satVal.textContent = '0';
              syncWheelTo(0);
            } else {
              // Color mode: restore saturation if 0, sync wheel to 0° (mode resets offset)
              restoreSatIfZero();
              syncWheelTo(0);
            }
            scheduleURLUpdate();
          });
          modeContainer.appendChild(btn);
        });
      }
    }

    function buildControlPanel() {
      const container = document.getElementById('cpSliders');
      container.innerHTML = '';

      for (const [groupName, sliders] of Object.entries(SLIDER_GROUPS)) {
        const group = document.createElement('div');
        group.className = 'cp-group';

        const title = document.createElement('div');
        title.className = 'cp-group-title';
        title.textContent = groupName;
        group.appendChild(title);

        const content = document.createElement('div');
        content.className = 'cp-group-content';

        for (const def of sliders) {
          const row = document.createElement('div');
          row.className = 'cp-slider-row';

          const label = document.createElement('span');
          label.className = 'cp-label';
          label.textContent = def.label;
          label.title = def.key;

          const value = document.createElement('span');
          value.className = 'cp-value';
          value.id = 'cpVal_' + def.key;

          const input = document.createElement('input');
          input.type = 'range';
          input.min = def.min;
          input.max = def.max;
          input.step = def.step;
          input.value = def.default;
          input.id = 'cpSlider_' + def.key;

          // Read current value (JS getter or Ruby)
          const currentVal = def.getter ? def.getter() : window.rubyConfigGet?.(def.key);
          if (currentVal !== undefined && typeof currentVal === 'number') {
            input.value = currentVal;
          }
          value.textContent = Number(input.value).toFixed(def.step < 1 ? 2 : 0);

          input.addEventListener('input', function() {
            const v = Number(this.value);
            value.textContent = v.toFixed(def.step < 1 ? 2 : 0);
            if (def.setter) {
              def.setter(v);
            } else if (window.rubyConfigSet) {
              window.rubyConfigSet(def.key, v);
            }
            scheduleURLUpdate();
          });

          // Prevent keyboard events from propagating (avoid camera/color controls)
          input.addEventListener('keydown', function(e) { e.stopPropagation(); });

          row.appendChild(label);
          row.appendChild(input);
          row.appendChild(value);
          content.appendChild(row);
        }

        group.appendChild(content);
        container.appendChild(group);
      }

      // Wire action buttons
      document.getElementById('cpLoadVrmBtn').addEventListener('click', triggerVRMFileLoad);
      document.getElementById('cpCaptureTabBtn').addEventListener('click', toggleTabCapture);
      document.getElementById('cpCaptureCameraBtn').addEventListener('click', toggleCameraCapture);
      document.getElementById('cpPerfViewBtn').addEventListener('click', togglePerfView);

      // Wire Audio Source buttons
      // Mic: toggle mic source on/off
      document.getElementById('cpSrcMic').addEventListener('click', () => {
        toggleMicSource();
      });
      // ⚙: open mic device picker
      document.getElementById('cpMicDeviceBtn').addEventListener('click', (e) => {
        e.stopPropagation();
        showMicDevicePicker();
      });
      // Cam Mic: toggle camera mic audio
      document.getElementById('cpSrcCamera').addEventListener('click', () => {
        toggleCamMic();
      });
      // Tab: toggle tab capture
      document.getElementById('cpSrcTab').addEventListener('click', () => {
        toggleTabCapture();
      });

      // Wire close and reset buttons
      document.getElementById('cpCloseBtn').addEventListener('click', toggleControlPanel);
      document.getElementById('cpResetBtn').addEventListener('click', function() {
        if (window.rubyConfigReset) window.rubyConfigReset();
        // Reset JS-side sliders (Camera) to defaults
        for (const sliders of Object.values(SLIDER_GROUPS)) {
          for (const def of sliders) {
            if (def.setter) def.setter(def.default);
          }
        }
        syncControlPanelValues();
        scheduleURLUpdate();
      });

      // Initialize hue wheel
      initHueWheel();
    }

    function syncControlPanelValues() {
      for (const sliders of Object.values(SLIDER_GROUPS)) {
        for (const def of sliders) {
          const slider = document.getElementById('cpSlider_' + def.key);
          const valueEl = document.getElementById('cpVal_' + def.key);
          if (slider && valueEl) {
            const currentVal = def.getter ? def.getter() : window.rubyConfigGet?.(def.key);
            if (currentVal !== undefined && typeof currentVal === 'number') {
              slider.value = currentVal;
              valueEl.textContent = currentVal.toFixed(def.step < 1 ? 2 : 0);
            } else {
              slider.value = def.default;
              valueEl.textContent = Number(def.default).toFixed(def.step < 1 ? 2 : 0);
            }
          }
        }
      }
      // Sync Color group sliders (brightness/saturation) from Ruby
      ['max_brightness', 'max_saturation'].forEach(id => {
        const slider = document.getElementById('cpSlider_' + id);
        const valueEl = document.getElementById('cpVal_' + id);
        if (slider && valueEl) {
          const v = window.rubyConfigGet?.(id);
          if (v !== undefined && typeof v === 'number') {
            slider.value = v;
            valueEl.textContent = Math.round(v);
          }
        }
      });
    }

    function toggleControlPanel() {
      controlPanelOpen = !controlPanelOpen;
      const panel = document.getElementById('controlPanel');
      if (controlPanelOpen) {
        panel.classList.add('active');
        syncControlPanelValues();
      } else {
        panel.classList.remove('active');
      }
    }

    // Handle window resize
    window.addEventListener('resize', function() {
      // Skip if Three.js not yet initialized
      if (!camera || !renderer || !composer) return;

      const width = window.innerWidth;
      const height = window.innerHeight;
      camera.aspect = width / height;
      camera.updateProjectionMatrix();
      renderer.setSize(width, height);
      composer.setSize(width, height);
    });

    // Start initialization when page loads
    window.addEventListener('DOMContentLoaded', init);
  </script>
</body>
</html>
